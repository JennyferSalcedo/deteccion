{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-18T17:40:13.571458Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D,Dropout,BatchNormalization\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "image_size = [128,128]\n",
    "data_path = './Basededatos/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "conv = VGG16(input_shape= image_size+[3],weights='imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 4, 4, 512) dtype=float32 (created by layer 'block5_pool')>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "for layer in conv.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "x = conv.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024,activation='relu')(x)\n",
    "x = Dense(1024,activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x=  Dropout(.2)(x)\n",
    "pred = Dense(2,activation='softmax')(x)\n",
    "model = Model(inputs = conv.input,outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_5  (None, 512)               0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16815426 (64.15 MB)\n",
      "Trainable params: 2100738 (8.01 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 471 images belonging to 2 classes.\n",
      "Found 117 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory('./Basededatos/', target_size=(128,128),  shuffle=False, subset='training', batch_size=10, class_mode='categorical')\n",
    "val_generator = train_datagen.flow_from_directory('./Basededatos/', target_size=(128,128),  shuffle=False, subset='validation', batch_size=10, class_mode='categorical')\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471\n",
      "10\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.n)\n",
    "print(train_generator.batch_size)\n",
    "print(242//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "10\n",
      "{'Con tumor': 0, 'Sin tumor': 1}\n"
     ]
    }
   ],
   "source": [
    "print(val_generator.n)\n",
    "print(val_generator.batch_size)\n",
    "#Next we have to create a labels.txt file that will hold all our labels (important for Flutter)\n",
    "print(train_generator.class_indices) #prints every single key and class of that dataset\n",
    "labels = '\\n'.join(sorted(train_generator.class_indices.keys())) #print all these keys as a list of labels into a text file called labels.txt\n",
    "with open('labels.txt', 'w') as f: #writes to the labels.txt file, and if it doesnt exists, it creates one, and if it does exist, it will overrite it. (thats what 'w' is for)\n",
    "    f.write(labels)\n",
    "\n",
    "#preprocessing of raw data is hence complete and now its time to build our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "47/47 [==============================] - 13s 266ms/step - loss: 2.6875 - accuracy: 0.7744 - val_loss: 0.4807 - val_accuracy: 0.8291\n",
      "Epoch 2/60\n",
      "47/47 [==============================] - 13s 268ms/step - loss: 0.4725 - accuracy: 0.8286 - val_loss: 0.3739 - val_accuracy: 0.8376\n",
      "Epoch 3/60\n",
      "47/47 [==============================] - 12s 262ms/step - loss: 0.3159 - accuracy: 0.8677 - val_loss: 0.5129 - val_accuracy: 0.7179\n",
      "Epoch 4/60\n",
      "47/47 [==============================] - 12s 258ms/step - loss: 0.2817 - accuracy: 0.9046 - val_loss: 0.3641 - val_accuracy: 0.8803\n",
      "Epoch 5/60\n",
      "47/47 [==============================] - 13s 276ms/step - loss: 0.4219 - accuracy: 0.8547 - val_loss: 0.3126 - val_accuracy: 0.8376\n",
      "Epoch 6/60\n",
      "47/47 [==============================] - 12s 264ms/step - loss: 0.4459 - accuracy: 0.8742 - val_loss: 0.4877 - val_accuracy: 0.8291\n",
      "Epoch 7/60\n",
      "47/47 [==============================] - 12s 263ms/step - loss: 0.4348 - accuracy: 0.8612 - val_loss: 0.3684 - val_accuracy: 0.8718\n",
      "Epoch 8/60\n",
      "47/47 [==============================] - 12s 266ms/step - loss: 0.2519 - accuracy: 0.9132 - val_loss: 0.3495 - val_accuracy: 0.8547\n",
      "Epoch 9/60\n",
      "47/47 [==============================] - 13s 269ms/step - loss: 0.1913 - accuracy: 0.9328 - val_loss: 0.5348 - val_accuracy: 0.8376\n",
      "Epoch 10/60\n",
      "47/47 [==============================] - 12s 264ms/step - loss: 0.4545 - accuracy: 0.8460 - val_loss: 0.2820 - val_accuracy: 0.8632\n",
      "Epoch 11/60\n",
      "47/47 [==============================] - 12s 259ms/step - loss: 0.2460 - accuracy: 0.9089 - val_loss: 0.3626 - val_accuracy: 0.8803\n",
      "Epoch 12/60\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.2726 - accuracy: 0.8937 - val_loss: 0.4651 - val_accuracy: 0.7778\n",
      "Epoch 13/60\n",
      "47/47 [==============================] - 12s 258ms/step - loss: 0.2398 - accuracy: 0.8980 - val_loss: 0.2901 - val_accuracy: 0.9060\n",
      "Epoch 14/60\n",
      "47/47 [==============================] - 12s 260ms/step - loss: 0.2156 - accuracy: 0.9241 - val_loss: 0.3984 - val_accuracy: 0.8632\n",
      "Epoch 15/60\n",
      "47/47 [==============================] - 12s 261ms/step - loss: 0.2341 - accuracy: 0.9132 - val_loss: 0.2509 - val_accuracy: 0.8974\n",
      "Epoch 16/60\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.2780 - accuracy: 0.8785 - val_loss: 0.2861 - val_accuracy: 0.8803\n",
      "Epoch 17/60\n",
      "47/47 [==============================] - 13s 269ms/step - loss: 0.2294 - accuracy: 0.9111 - val_loss: 0.3011 - val_accuracy: 0.8632\n",
      "Epoch 18/60\n",
      "47/47 [==============================] - 12s 261ms/step - loss: 0.2274 - accuracy: 0.9089 - val_loss: 0.3483 - val_accuracy: 0.8632\n",
      "Epoch 19/60\n",
      "47/47 [==============================] - 12s 263ms/step - loss: 0.2323 - accuracy: 0.8937 - val_loss: 0.2499 - val_accuracy: 0.9145\n",
      "Epoch 20/60\n",
      "47/47 [==============================] - 12s 263ms/step - loss: 0.1910 - accuracy: 0.9241 - val_loss: 0.3008 - val_accuracy: 0.8974\n",
      "Epoch 21/60\n",
      "47/47 [==============================] - 12s 262ms/step - loss: 0.1906 - accuracy: 0.9132 - val_loss: 0.3276 - val_accuracy: 0.8974\n",
      "Epoch 22/60\n",
      "47/47 [==============================] - 12s 266ms/step - loss: 0.1806 - accuracy: 0.9328 - val_loss: 0.2253 - val_accuracy: 0.9060\n",
      "Epoch 23/60\n",
      "47/47 [==============================] - 12s 262ms/step - loss: 0.1987 - accuracy: 0.9197 - val_loss: 0.3218 - val_accuracy: 0.8632\n",
      "Epoch 24/60\n",
      "47/47 [==============================] - 12s 262ms/step - loss: 0.1767 - accuracy: 0.9306 - val_loss: 0.3541 - val_accuracy: 0.8803\n",
      "Epoch 25/60\n",
      "47/47 [==============================] - 12s 263ms/step - loss: 0.1882 - accuracy: 0.9284 - val_loss: 0.2794 - val_accuracy: 0.9231\n",
      "Epoch 26/60\n",
      "47/47 [==============================] - 12s 262ms/step - loss: 0.1882 - accuracy: 0.9262 - val_loss: 0.2553 - val_accuracy: 0.8889\n",
      "Epoch 27/60\n",
      "47/47 [==============================] - 12s 265ms/step - loss: 0.1661 - accuracy: 0.9284 - val_loss: 0.4404 - val_accuracy: 0.8376\n",
      "Epoch 28/60\n",
      "47/47 [==============================] - 12s 263ms/step - loss: 0.1965 - accuracy: 0.9111 - val_loss: 0.3065 - val_accuracy: 0.8974\n",
      "Epoch 29/60\n",
      "47/47 [==============================] - 12s 259ms/step - loss: 0.2240 - accuracy: 0.8959 - val_loss: 0.3694 - val_accuracy: 0.8889\n",
      "Epoch 30/60\n",
      "47/47 [==============================] - 12s 258ms/step - loss: 0.1952 - accuracy: 0.9024 - val_loss: 0.2774 - val_accuracy: 0.8974\n",
      "Epoch 31/60\n",
      "47/47 [==============================] - 12s 260ms/step - loss: 0.2522 - accuracy: 0.9089 - val_loss: 0.4252 - val_accuracy: 0.8718\n",
      "Epoch 32/60\n",
      "47/47 [==============================] - 12s 258ms/step - loss: 0.2152 - accuracy: 0.9089 - val_loss: 0.3242 - val_accuracy: 0.8974\n",
      "Epoch 33/60\n",
      "47/47 [==============================] - 12s 257ms/step - loss: 0.1608 - accuracy: 0.9262 - val_loss: 0.3419 - val_accuracy: 0.8889\n",
      "Epoch 34/60\n",
      "47/47 [==============================] - 12s 259ms/step - loss: 0.2116 - accuracy: 0.9176 - val_loss: 0.3912 - val_accuracy: 0.8547\n",
      "Epoch 35/60\n",
      "47/47 [==============================] - 13s 268ms/step - loss: 0.1544 - accuracy: 0.9328 - val_loss: 0.2827 - val_accuracy: 0.9060\n",
      "Epoch 36/60\n",
      "47/47 [==============================] - 12s 264ms/step - loss: 0.1772 - accuracy: 0.9284 - val_loss: 0.2952 - val_accuracy: 0.8718\n",
      "Epoch 37/60\n",
      "47/47 [==============================] - 12s 262ms/step - loss: 0.1226 - accuracy: 0.9566 - val_loss: 0.2474 - val_accuracy: 0.8889\n",
      "Epoch 38/60\n",
      "47/47 [==============================] - 12s 266ms/step - loss: 0.2210 - accuracy: 0.9234 - val_loss: 0.3769 - val_accuracy: 0.8974\n",
      "Epoch 39/60\n",
      "47/47 [==============================] - 12s 262ms/step - loss: 0.1982 - accuracy: 0.9284 - val_loss: 0.2987 - val_accuracy: 0.9060\n",
      "Epoch 40/60\n",
      "47/47 [==============================] - 12s 262ms/step - loss: 0.1522 - accuracy: 0.9328 - val_loss: 0.2895 - val_accuracy: 0.8889\n",
      "Epoch 41/60\n",
      "47/47 [==============================] - 12s 265ms/step - loss: 0.1664 - accuracy: 0.9306 - val_loss: 0.2770 - val_accuracy: 0.8974\n",
      "Epoch 42/60\n",
      "47/47 [==============================] - 12s 263ms/step - loss: 0.2106 - accuracy: 0.8959 - val_loss: 0.2363 - val_accuracy: 0.8718\n",
      "Epoch 43/60\n",
      "47/47 [==============================] - 12s 267ms/step - loss: 0.1618 - accuracy: 0.9284 - val_loss: 0.3281 - val_accuracy: 0.8547\n",
      "Epoch 44/60\n",
      "47/47 [==============================] - 12s 263ms/step - loss: 0.1521 - accuracy: 0.9284 - val_loss: 0.3170 - val_accuracy: 0.9231\n",
      "Epoch 45/60\n",
      "47/47 [==============================] - 12s 264ms/step - loss: 0.1511 - accuracy: 0.9262 - val_loss: 0.3397 - val_accuracy: 0.8632\n",
      "Epoch 46/60\n",
      "47/47 [==============================] - 13s 267ms/step - loss: 0.1260 - accuracy: 0.9371 - val_loss: 0.4042 - val_accuracy: 0.8718\n",
      "Epoch 47/60\n",
      "47/47 [==============================] - 12s 262ms/step - loss: 0.1674 - accuracy: 0.9262 - val_loss: 0.3537 - val_accuracy: 0.8974\n",
      "Epoch 48/60\n",
      "47/47 [==============================] - 12s 265ms/step - loss: 0.1757 - accuracy: 0.9132 - val_loss: 0.3234 - val_accuracy: 0.9060\n",
      "Epoch 49/60\n",
      "47/47 [==============================] - 12s 263ms/step - loss: 0.1520 - accuracy: 0.9241 - val_loss: 0.2633 - val_accuracy: 0.8632\n",
      "Epoch 50/60\n",
      "47/47 [==============================] - 12s 263ms/step - loss: 0.1496 - accuracy: 0.9284 - val_loss: 0.2756 - val_accuracy: 0.8974\n",
      "Epoch 51/60\n",
      "47/47 [==============================] - 12s 263ms/step - loss: 0.1642 - accuracy: 0.9284 - val_loss: 0.6757 - val_accuracy: 0.8376\n",
      "Epoch 52/60\n",
      "47/47 [==============================] - 12s 263ms/step - loss: 0.2370 - accuracy: 0.9111 - val_loss: 0.3090 - val_accuracy: 0.8889\n",
      "Epoch 53/60\n",
      "47/47 [==============================] - 12s 265ms/step - loss: 0.1394 - accuracy: 0.9458 - val_loss: 0.3229 - val_accuracy: 0.8889\n",
      "Epoch 54/60\n",
      "47/47 [==============================] - 12s 264ms/step - loss: 0.1442 - accuracy: 0.9328 - val_loss: 0.3639 - val_accuracy: 0.8803\n",
      "Epoch 55/60\n",
      "47/47 [==============================] - 13s 267ms/step - loss: 0.1667 - accuracy: 0.9197 - val_loss: 0.2455 - val_accuracy: 0.8803\n",
      "Epoch 56/60\n",
      "47/47 [==============================] - 12s 265ms/step - loss: 0.1465 - accuracy: 0.9306 - val_loss: 0.3616 - val_accuracy: 0.8974\n",
      "Epoch 57/60\n",
      "47/47 [==============================] - 12s 264ms/step - loss: 0.2005 - accuracy: 0.9067 - val_loss: 0.2850 - val_accuracy: 0.8718\n",
      "Epoch 58/60\n",
      "47/47 [==============================] - 12s 264ms/step - loss: 0.1405 - accuracy: 0.9328 - val_loss: 0.3209 - val_accuracy: 0.9060\n",
      "Epoch 59/60\n",
      "47/47 [==============================] - 12s 264ms/step - loss: 0.1293 - accuracy: 0.9349 - val_loss: 0.2992 - val_accuracy: 0.9231\n",
      "Epoch 60/60\n",
      "47/47 [==============================] - 12s 264ms/step - loss: 0.1388 - accuracy: 0.9371 - val_loss: 0.4248 - val_accuracy: 0.8803\n"
     ]
    }
   ],
   "source": [
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "history = model.fit_generator(generator=train_generator, steps_per_epoch=step_size_train, epochs=60,  verbose=1, validation_data=val_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "t = f.suptitle('VGG16', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "epoch_list = list(range(0, len(history.history['accuracy'])))\n",
    "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(0, len(history.history['accuracy']), 5))\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
    "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(0, len(history.history['accuracy']), 5))\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict_generator(val_generator, val_generator.n // val_generator.batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(val_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[90  7]\n",
      " [ 3 17]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(val_generator.classes, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Tumor       0.97      0.93      0.95        97\n",
      "       Tumor       0.71      0.85      0.77        20\n",
      "\n",
      "    accuracy                           0.91       117\n",
      "   macro avg       0.84      0.89      0.86       117\n",
      "weighted avg       0.92      0.91      0.92       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "target_names = ['No Tumor', 'Tumor']\n",
    "print(classification_report(val_generator.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(700.5483091787441, 0.5, 'True Values')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "cm=confusion_matrix(val_generator.classes, y_pred)\n",
    "sns.heatmap(cm, square=True, annot=True, cbar=False, cmap=plt.cm.Blues)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('True Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Tumor'), Text(0, 1.5, 'No Tumor')]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['No Tumor', 'Tumor']); ax.yaxis.set_ticklabels(['Tumor', 'No Tumor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[90  7]\n",
      " [ 3 17]]\n",
      "Accuracy Score : 0.9145299145299145\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95        97\n",
      "           1       0.71      0.85      0.77        20\n",
      "\n",
      "    accuracy                           0.91       117\n",
      "   macro avg       0.84      0.89      0.86       117\n",
      "weighted avg       0.92      0.91      0.92       117\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Confusion Matrix'}>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "results = confusion_matrix(val_generator.classes,y_pred) \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :',accuracy_score(val_generator.classes,y_pred)) \n",
    "print('Report : ')\n",
    "print(classification_report(val_generator.classes,y_pred))\n",
    "\n",
    "sns.heatmap(results/np.sum(results), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8889175257731959"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(val_generator.classes, y_pred, pos_label=1)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(fpr, tpr)\n",
    "ax.plot(np.linspace(0, 1, 100),\n",
    "         np.linspace(0, 1, 100),\n",
    "         label='baseline',\n",
    "         linestyle='--')\n",
    "plt.title('Receiver Operating Characteristic Curve', fontsize=14)\n",
    "plt.ylabel('Total Positive Rate', fontsize=12)\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.legend(fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Vgg16Detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "model = load_model('Vgg16Detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Con tumor', 'Sin tumor']\n"
     ]
    }
   ],
   "source": [
    "def load_labels(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        labels = f.read().splitlines()\n",
    "    return labels\n",
    "\n",
    "# Especifica la ruta del archivo labels.txt\n",
    "labels_file = 'labels.txt'\n",
    "\n",
    "# Carga las clases desde el archivo labels.txt\n",
    "class_names = load_labels(labels_file)\n",
    "\n",
    "# Verifica las clases cargadas\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img):\n",
    "  img_4d=img.reshape(-1,128,128,3)\n",
    "  prediction=model.predict(img_4d)[0]\n",
    "  return {class_names[i]: float(prediction[i]) for i in range(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "def predict_image(img):\n",
    "    img_resized = cv2.resize(img, (128, 128))  # Redimensionar la imagen a 128x128\n",
    "    img_resized = img_resized / 255.0  # Normalizar los valores de píxeles entre 0 y 1\n",
    "    img_resized = np.expand_dims(img_resized, axis=0)  # Agregar una dimensión adicional para el tamaño del lote\n",
    "\n",
    "    # Realizar la predicción utilizando el modelo\n",
    "    predictions = model.predict(img_resized)\n",
    "    predicted_class = np.argmax(predictions)  # Obtener el índice de la clase predicha\n",
    "    confidence = float(predictions[0, predicted_class])  # Obtener la confianza de la predicción\n",
    "\n",
    "    label = class_names[predicted_class]  # Obtener la etiqueta correspondiente a la clase predicha\n",
    "\n",
    "    return {label: confidence}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "image = gr.inputs.Image(shape=(128, 128))\n",
    "label = gr.outputs.Label(num_top_classes=2)\n",
    "\n",
    "gr.Interface(fn=predict_image, inputs=image, outputs=label, interpretation='default').launch(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
